{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76b97814-8894-46a3-a505-688c9f1a1630",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (pywrap_tensorflow_internal.py, line 114)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn [1], line 1\u001b[0m\n    from keras.preprocessing.image import load_img, img_to_array\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/__init__.py:20\u001b[0m\n    from keras import distribute\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/distribute/__init__.py:18\u001b[0m\n    from keras.distribute import sidecar_evaluator\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/distribute/sidecar_evaluator.py:17\u001b[0m\n    import tensorflow.compat.v2 as tf\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/__init__.py:24\u001b[0m\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py:49\u001b[0m\n    from tensorflow.python import pywrap_tensorflow\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:58\u001b[0;36m\n\u001b[0;31m    from tensorflow.python.pywrap_tensorflow_internal import *\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:114\u001b[0;36m\u001b[0m\n\u001b[0;31m    def TFE_ContextOptionsSetAsync(arg1, async):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "\n",
    "target_image_path = 'luda.jpg'\n",
    "style_reference_image_path = 'img/transfer_style_reference.jpg'\n",
    "\n",
    "width, height = load_img(target_image_path).size\n",
    "img_height = 400\n",
    "img_width = int(width * img_height / height)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420b6fa7-152b-4728-9492-62974751e42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.applications import vgg19\n",
    "\n",
    "def preprocess_image(image_path):\n",
    "    img = load_image(image_path, target_size=(img_height, img_width))\n",
    "    img = img_to_array(img)\n",
    "    img = np.expand_dims(img, axis=0)\n",
    "    img = vgg19.preprocess_input(img)\n",
    "    return img\n",
    "\n",
    "def deprocess_image(x):\n",
    "    x[:, :, 0] += 103.939\n",
    "    x[:, :, 1] += 116.779\n",
    "    x[:, :, 2] += 123.68\n",
    "    x = x[:, :, ::-1]\n",
    "    x = np.clip(x, 0, 255).astype('uint8')\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1caf5d28-ed31-4be2-8b0d-984b651d79fb",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (pywrap_tensorflow_internal.py, line 114)",
     "output_type": "error",
     "traceback": [
      "Traceback \u001b[0;36m(most recent call last)\u001b[0m:\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/IPython/core/interactiveshell.py:3378\u001b[0m in \u001b[1;35mrun_code\u001b[0m\n    exec(code_obj, self.user_global_ns, self.user_ns)\u001b[0m\n",
      "\u001b[0m  Cell \u001b[1;32mIn [2], line 1\u001b[0m\n    from keras import backend as k\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/__init__.py:20\u001b[0m\n    from keras import distribute\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/distribute/__init__.py:18\u001b[0m\n    from keras.distribute import sidecar_evaluator\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/keras/distribute/sidecar_evaluator.py:17\u001b[0m\n    import tensorflow.compat.v2 as tf\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/__init__.py:24\u001b[0m\n    from tensorflow.python import pywrap_tensorflow  # pylint: disable=unused-import\u001b[0m\n",
      "\u001b[0m  File \u001b[1;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/__init__.py:49\u001b[0m\n    from tensorflow.python import pywrap_tensorflow\u001b[0m\n",
      "\u001b[0;36m  File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow.py:58\u001b[0;36m\n\u001b[0;31m    from tensorflow.python.pywrap_tensorflow_internal import *\u001b[0;36m\n",
      "\u001b[0;36m  File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/tensorflow/python/pywrap_tensorflow_internal.py:114\u001b[0;36m\u001b[0m\n\u001b[0;31m    def TFE_ContextOptionsSetAsync(arg1, async):\u001b[0m\n\u001b[0m                                         ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from keras import backend as k\n",
    "\n",
    "target_image = k.contant(preprocess_image(targe_image_path))\n",
    "style_reference_image = k.constant(preprocess_image(style_reference_image_path))\n",
    "combination_image = k.placeholder((1, img_height, img_width, 3))\n",
    "\n",
    "input_sensor = k.concatenate([target_name,\n",
    "                              style_reference_image,\n",
    "                              combination_image], axis=0)\n",
    "\n",
    "model = vgg19.VGG19(input_tensor=input_tensor,\n",
    "                    weights='imagenet',\n",
    "                    include_top=False)\n",
    "print('Model zostal zaladowany.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6004bd2-6e9e-407e-879b-cabcbc7b33b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def content_loss(base, combination):\n",
    "    return k.sum(k.square(combination - base))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c4e05136-b512-4bc9-9401-05872975d5b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gram_style(x):\n",
    "    features = k.batch_flatten(k.permute_dimensions(x, (2, 0, 1)))\n",
    "    gram = k.dot(features, k.transpose(features))\n",
    "    return gram\n",
    "\n",
    "def style_loss(style, combination):\n",
    "    S = gram_matrix(style)\n",
    "    C = gram_matrix(combination)\n",
    "    channels = 3\n",
    "    size = img_height * img_width\n",
    "    return k.sum(k.square(S-C)) / (4.*(channels ** 2) * (size ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3e08c0a0-dba7-4780-b8e6-85332c42f812",
   "metadata": {},
   "outputs": [],
   "source": [
    "def total_variation_loss(x):\n",
    "    a = k.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, 1, :img_width - 1, :])\n",
    "    b = k.square(\n",
    "        x[:, :img_height - 1, :img_width - 1, :] - x[:, :img_height - 1, 1:, :])\n",
    "    return k.sum(k.pow(a + b, 1.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50742951-7590-44e1-ae81-8ffdb91416aa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m outputs_dict \u001b[38;5;241m=\u001b[39m ([(layer\u001b[38;5;241m.\u001b[39mname, layer\u001b[38;5;241m.\u001b[39moutput) \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m \u001b[43mmodel\u001b[49m\u001b[38;5;241m.\u001b[39mlayers])\n\u001b[1;32m      2\u001b[0m content_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock5_conv2\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      3\u001b[0m style_layers \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock1_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      4\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock2_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock3_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      6\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock4_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      7\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mblock5_conv1\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "outputs_dict = ([(layer.name, layer.output) for layer in model.layers])\n",
    "content_layer = 'block5_conv2'\n",
    "style_layers = ['block1_conv1',\n",
    "                'block2_conv1',\n",
    "                'block3_conv1',\n",
    "                'block4_conv1',\n",
    "                'block5_conv1']\n",
    "total_variation_weight = 1e-4\n",
    "style_weight = 1.\n",
    "content_weight = 0.025\n",
    "\n",
    "loss = k.variable(0.)\n",
    "\n",
    "layer_features = outputs_dict[content_layer]\n",
    "target_image_features = layer_features[1, :, :, :]\n",
    "combination_features = layer_features[2, :, :, :]\n",
    "loss += content_weight * content_loss(target_image_features,\n",
    "                                      combination_features)\n",
    "\n",
    "for layer_name in style_layers:\n",
    "    layer_features = outputs_dict[layer_name]\n",
    "    style_reference_features = layer_features[1, :, :, :]\n",
    "    combination_features = layer_features[2, :, :, :]\n",
    "    sl = style_loss(style_reference_features, combination_features)\n",
    "    loss += (style_weight / len(style_layers)) * sl\n",
    "\n",
    "loss += total_variation_weight * total_variation_loss(combination_image)\n",
    "    \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b266bc08-7e25-4679-8ead-6c4ec8ffe7cb",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m grads \u001b[38;5;241m=\u001b[39m \u001b[43mk\u001b[49m\u001b[38;5;241m.\u001b[39mgradients(loss, combination_image)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m      3\u001b[0m fetch_loss_and_grads \u001b[38;5;241m=\u001b[39m k\u001b[38;5;241m.\u001b[39mfunction([combination_image], [loss, grads])\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mEvaluation\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "grads = k.gradients(loss, combination_image)[0]\n",
    "\n",
    "fetch_loss_and_grads = k.function([combination_image], [loss, grads])\n",
    "\n",
    "class Evaluation(object):\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.loss_value = None\n",
    "        self.grads_values = None\n",
    "        \n",
    "    def loss(self, x):\n",
    "        assert self.loss_value is None\n",
    "        x = x.reshape((1, img_height, img_width, 3))\n",
    "        outs = fetch_loss_and_grads([x])\n",
    "        loss_value = outs[0]\n",
    "        grad_values = outs[0].flatten().astype('float64')\n",
    "        self.loss_value = loss_value\n",
    "        self.grad_values = grad_values\n",
    "        return self.loss_value\n",
    "    \n",
    "    def grads(self, x):\n",
    "        assert self.loss_value is not None\n",
    "        grad_values = np.copy(self.grad_values)\n",
    "        self.loss_value = None\n",
    "        self.grad_values = None\n",
    "        return grad_values\n",
    "\n",
    "evaluator = Evaluator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd676bde-3759-412a-a29b-5b178411bbb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import fmin_1_bfgs_b\n",
    "from scipy.misc import imsave\n",
    "import time\n",
    "\n",
    "result_prefix = 'style_transfer_result'\n",
    "iterations = 20\n",
    "\n",
    "x = preprocess_image(target_image_path)\n",
    "x = x.flatten()\n",
    "\n",
    "for i in range(iterations):\n",
    "    print('Poczatek iteracji numer', i)\n",
    "    start_time = time.time()\n",
    "    x, min_val, info = fmin_1_bfgs_b(evaluator.loss, x,\n",
    "                                     fprime=evaluator.grads,\n",
    "                                     maxfun=20)\n",
    "    print('Aktualna wartosc starty:', min_val)\n",
    "img = x.copy().reshape((img.height, img_width, 3))\n",
    "img = deprocess_image(img)\n",
    "fname = result_prefix + '_at_iteration_%d.png' % i\n",
    "imsave(fname, img)\n",
    "end_time = time.time()\n",
    "print('Obraz zapisany w pliku', fname)\n",
    "print('Iteracja numer %d zostala zakonczona w czasie %ds' % (i, end_time - start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
